# Paper_Bert-based-Classification-Model-Improvement-through-Minority-Class-Data-Augmentation

## 논문 요약
자연어처리 분야에서 딥러닝 기반의 분류 모델은 획기적인 성능을 보여주고 있다. 특히 2018 년
발표된 구글의 BERT 는 다양한 태스크에서 높은 성능을 보여준다. 본 논문에서는 이러한
BERT 가 클래스 불균형이 심한 데이터에 대해 어느 정도 성능을 보여주는지 확인하고 이를
해결하는 방법으로 EDA 를 선택해 성능을 개선하고자 한다. BERT 에 알맞게 적용하기 위해
다양한 방법으로 EDA 를 구현했고 이에 대한 성능을 평가하였다. 

### 1. 서론 
모든 뉴럴 네트워크가 그렇듯 BERT 역시 학습시키는 데이터의 클래스가 비슷한 비율로
구성되어 있지 않으면 모델의 성능이 저하되게 된다. 이와 같은 문제를 데이터 불균형 
문제라고 하며 소수 클래스에 속하는 데이터들이 다수 클래스에 속하는 데이터보다 잘못
분류되는 경우가 생길 수 있다[4]. 이를 해결하기 위해 더 많은 데이터를 수집하거나
성능지표를 변경하는 등의 다양한 기법들이 존재한다. 본 논문에서는 다양한 데이터 불
균형 처리 기법을 BERT 모델 맞게 적용해 실험하고 결과를 비교하는 것을 목표로 한다.
